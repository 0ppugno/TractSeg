#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2017 Division of Medical Image Computing, German Cancer Research Center (DKFZ)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import importlib
import argparse
import pickle
import warnings
import time
from pprint import pprint
import distutils.util
from os.path import join
import nibabel as nib
import numpy as np

from tractseg.libs.DirectionMerger import DirectionMerger
from tractseg.libs.ExpUtils import ExpUtils
from tractseg.libs.ImgUtils import ImgUtils
from tractseg.libs.MetricUtils import MetricUtils
from tractseg.libs.Config import Config as C
from tractseg.libs.Trainer import Trainer
from tractseg.libs.DataManagers import DataManagerSingleSubjectById
from tractseg.libs.DataManagers import DataManagerTrainingNiftiImgs
from tractseg.libs.DataManagers import DataManagerPrecomputedBatches
from tractseg.libs.DataManagers import DataManagerPrecomputedBatches_noDLBG

'''
Adapt for Peak Prediction (after Training):
- set: DATASET_FOLDER = "HCP"
- command: ExpRunner --train=False --test=False --probs --lw --en HCP_Peaks_Y
'''

'''
Adapt for DM Regression:
- SlicesBatchGeneratorRandomNiftiImg: only y direction instead of random
- HP.NR_OF_CLASSES: remove 3*
- ExpRunner: Use DataManagerTrainingNiftiImgs
- LABELS_FILENAME = "bundle_masks_dm"
- INFO
- ExpRunner: Comment ImgUtils.save_multilabel_img_as_multiple_files_peaks
'''

'''
Adapt for SingleClass Peaks:
- SlicesBatchGeneratorRandomNiftiImg: only y direction instead of random
- adapt ExpUtils.get_bundle_names
- adapt LABELS_FILENAME
- DATASET_FOLDER = "HCP"
- HP.NR_OF_CLASSES: 3*
- ExpRunner: Use ImgUtils.save_multilabel_img_as_multiple_files_peaks
- PRINT_FREQ = 20

- If 32g_25mm
    - FEATURES_FILENAME = "32g_25mm_peaks"
    - DATASET = "HCP_32g"
    - RESOLUTION = "2.5mm"
    - INPUT_DIM = (80, 80)
'''

'''
Adapt for 11 Classes:
- adapt ExpUtils.get_bundle_names
- adapt LABELS_FILENAME
- if doing 32g_25mm:
    - comment scale_input_to_unet_shape() in BatchGenerators for seg
'''

warnings.simplefilter("ignore", UserWarning)    #hide scipy warnings

parser = argparse.ArgumentParser(description="Train a network on your own data to segment white matter bundles.",
                                    epilog="Written by Jakob Wasserthal. Please reference 'Wasserthal et al. " +
                                           "Direct White Matter Bundle Segmentation using Stacked U-Nets. https://arxiv.org/abs/1703.02036)'")
parser.add_argument("--config", metavar="name", help="Name of configuration to use")
parser.add_argument("--train", metavar="True/False", help="Train network", type=distutils.util.strtobool, default=True)
parser.add_argument("--test", metavar="True/False", help="Test network", type=distutils.util.strtobool, default=False)
parser.add_argument("--seg", action="store_true", help="Create binary segmentation", default=False)
# parser.add_argument("--probs", action="store_true", help="Create probmap segmentation", default=False)
parser.add_argument("--lw", action="store_true", help="Load weights of pretrained net", default=False)
parser.add_argument("--en", metavar="name", help="Experiment name")
# parser.add_argument("--fold", metavar="N", help="Which fold to train when doing CrossValidation", type=int, default=0)
parser.add_argument("--verbose", action="store_true", help="Show more intermediate output", default=True)
parser.add_argument('--version', action='version', version='TractSeg 0.5')
args = parser.parse_args()

HP = getattr(importlib.import_module("tractseg.config.BaseHP"), "HP")()
if args.config:
    HP = getattr(importlib.import_module("tractseg.config.custom." + args.config), "HP")()    #HP.__dict__ does not work if ()
    # HP.EXP_NAME = args.config

if args.en:
    HP.EXP_NAME = args.en

HP.TRAIN = bool(args.train)
HP.TEST = bool(args.test)
HP.SEGMENT = args.seg
# HP.GET_PROBS = args.probs
HP.LOAD_WEIGHTS = args.lw
# HP.CV_FOLD= args.fold
HP.VERBOSE = args.verbose

HP.MULTI_PARENT_PATH = join(C.EXP_PATH, HP.EXP_MULTI_NAME)
HP.EXP_PATH = join(C.EXP_PATH, HP.EXP_MULTI_NAME, HP.EXP_NAME)
HP.TRAIN_SUBJECTS, HP.VALIDATE_SUBJECTS, HP.TEST_SUBJECTS = ExpUtils.get_cv_fold(HP.CV_FOLD)

if HP.WEIGHTS_PATH == "":
    HP.WEIGHTS_PATH = ExpUtils.get_best_weights_path(HP.EXP_PATH, HP.LOAD_WEIGHTS)

#Autoset some parameters based on settings
HP.INPUT_DIM = (144, 144) if HP.RESOLUTION == "1.25mm" else (80, 80)

if HP.CLASSES == "All" and HP.LABELS_TYPE == np.float32:
    if HP.RESOLUTION == "1.25mm":
        HP.LABELS_FILENAME = "bundle_peaks"
    else:
        HP.LABELS_FILENAME = "bundle_peaks_808080"

elif HP.CLASSES == "11":
    if HP.RESOLUTION == "1.25mm":
        HP.LABELS_FILENAME = "bundle_peaks_11"
    else:
        HP.LABELS_FILENAME = "bundle_peaks_11_808080"

elif HP.CLASSES == "20":
    if HP.RESOLUTION == "1.25mm":
        HP.LABELS_FILENAME = "bundle_peaks_20"
    else:
        HP.LABELS_FILENAME = "bundle_peaks_20_808080"

elif HP.CLASSES == "20_endpoints":
    if HP.RESOLUTION == "1.25mm":
        HP.LABELS_FILENAME = "endpoints_20"
    else:
        HP.LABELS_FILENAME = "endpoints_20"

elif HP.CLASSES == "20_endpoints_combined":
    if HP.RESOLUTION == "1.25mm":
        HP.LABELS_FILENAME = "endpoints_20_combined"
    else:
        HP.LABELS_FILENAME = "endpoints_20_combined"

elif HP.CLASSES == "20_bundles_endpoints":
    if HP.RESOLUTION == "1.25mm":
        HP.LABELS_FILENAME = "bundle_endpoints_20"
    else:
        HP.LABELS_FILENAME = "bundle_endpoints_20"

elif HP.CLASSES == "All" and HP.LABELS_TYPE == np.int16:
    if HP.RESOLUTION == "1.25mm":
        HP.LABELS_FILENAME = "bundle_peaks_72"
    else:
        HP.LABELS_FILENAME = "bundle_peaks_72"

else:
    HP.LABELS_FILENAME = "bundle_peaks/" + HP.CLASSES

#Peak Regression
if "peaks" in HP.LABELS_FILENAME:
    HP.NR_OF_CLASSES = 3*len(ExpUtils.get_bundle_names(HP.CLASSES)[1:])
# Classification/DM Regression
else:
    HP.NR_OF_CLASSES = len(ExpUtils.get_bundle_names(HP.CLASSES)[1:])

if HP.TRAIN:
    HP.EXP_PATH = ExpUtils.create_experiment_folder(HP.EXP_NAME, HP.MULTI_PARENT_PATH, HP.TRAIN)

if HP.VERBOSE:
    print("Hyperparameters:")
    ExpUtils.print_HPs(HP)

with open(join(HP.EXP_PATH, "Hyperparameters.txt"), "w") as f:
    HP_dict = {attr: getattr(HP, attr) for attr in dir(HP) if not callable(getattr(HP, attr)) and not attr.startswith("__")}
    pprint(HP_dict, f)

def test_whole_subject(HP, model, subjects, type):

    metrics = {
        "loss_" + type: [0],
        "f1_macro_" + type: [0],
    }

    # Metrics per bundle
    metrics_bundles = {}
    for bundle in ExpUtils.get_bundle_names(HP.CLASSES)[1:]:
        metrics_bundles[bundle] = [0]

    for subject in subjects:
        print("{} subject {}".format(type, subject))
        start_time = time.time()

        dataManagerSingle = DataManagerSingleSubjectById(HP, subject=subject)
        trainerSingle = Trainer(model, dataManagerSingle)
        img_probs, img_y = trainerSingle.get_seg_single_img(HP, probs=True)
        # img_probs_xyz, img_y = DirectionMerger.get_seg_single_img_3_directions(HP, model, subject=subject)
        # img_probs = DirectionMerger.mean_fusion(HP.THRESHOLD, img_probs_xyz, probs=True)

        print("Took {}s".format(round(time.time() - start_time, 2)))

        # img_probs = np.reshape(img_probs, (-1, img_probs.shape[-1]))  #Flatten all dims except nrClasses dim
        # img_y = np.reshape(img_y, (-1, img_y.shape[-1]))
        # metrics = MetricUtils.calculate_metrics(metrics, img_y, img_probs, 0, type=type, threshold=HP.THRESHOLD)
        # metrics_bundles = MetricUtils.calculate_metrics_each_bundle(metrics_bundles, img_y, img_probs, ExpUtils.get_bundle_names(HP.CLASSES), threshold=HP.THRESHOLD)

        f1 = MetricUtils.calc_peak_length_dice(HP, img_probs, img_y, max_angle_error=HP.PEAK_DICE_THR, max_length_error=HP.PEAK_DICE_LEN_THR)
        peak_f1_mean = np.array([s for s in f1.values()]).mean()  # if f1 for multiple bundles
        metrics = MetricUtils.calculate_metrics(metrics, None, None, 0, f1=peak_f1_mean, type=type, threshold=HP.THRESHOLD)
        metrics_bundles = MetricUtils.calculate_metrics_each_bundle(metrics_bundles, None, None, ExpUtils.get_bundle_names(HP.CLASSES)[1:], f1, threshold=HP.THRESHOLD)

    metrics = MetricUtils.normalize_last_element(metrics, len(subjects), type=type)
    metrics_bundles = MetricUtils.normalize_last_element_general(metrics_bundles, len(subjects))

    print("WHOLE SUBJECT:")
    pprint(metrics)
    print("WHOLE SUBJECT BUNDLES:")
    pprint(metrics_bundles)


    with open(join(HP.EXP_PATH, "score_" + type + "-set.txt"), "w") as f:
        pprint(metrics, f)
        f.write("\n\nWeights: {}\n".format(HP.WEIGHTS_PATH))
        f.write("type: {}\n\n".format(type))
        pprint(metrics_bundles, f)

    pickle.dump(metrics, open(join(HP.EXP_PATH, "score_" + type + ".pkl"), "wb"))

    return metrics

dataManager = DataManagerTrainingNiftiImgs(HP)
# dataManager = DataManagerPrecomputedBatches(HP)
# dataManager = DataManagerPrecomputedBatches_noDLBG(HP)
ModelClass = getattr(importlib.import_module("tractseg.models." + HP.MODEL), HP.MODEL)
model = ModelClass(HP)
trainer = Trainer(model, dataManager)

if HP.TRAIN:
    print("Training...")
    metrics = trainer.train(HP)

#After Training
if HP.TRAIN:
    # have to load other weights, because after training it has the weights of the last epoch
    print("Loading best epoch: {}".format(HP.BEST_EPOCH))
    HP.WEIGHTS_PATH = HP.EXP_PATH + "/best_weights_ep" + str(HP.BEST_EPOCH) + ".npz"
    HP.LOAD_WEIGHTS = True
    trainer.model.load_model(join(HP.EXP_PATH, HP.WEIGHTS_PATH))
    model_test = trainer.model
else:
    # Weight_path already set to best model (wenn reading program parameters) -> will be loaded automatically
    model_test = trainer.model

#todo important: change
#Old
if HP.SEGMENT:
    ExpUtils.make_dir(join(HP.EXP_PATH, "segmentations"))
    # all_subjects = HP.VALIDATE_SUBJECTS #+ HP.TEST_SUBJECTS
    all_subjects = ["599469"]
    # all_subjects = HP.TEST_SUBJECTS
    for subject in all_subjects:
        print("Get_segmentation subject {}".format(subject))
        start_time = time.time()

        dataManagerSingle = DataManagerSingleSubjectById(HP, subject=subject, use_gt_mask=False)
        trainerSingle = Trainer(model_test, dataManagerSingle)
        img_seg, img_y = trainerSingle.get_seg_single_img(HP, probs=False)  # only x or y or z
        # img_seg, img_y = DirectionMerger.get_seg_single_img_3_directions(HP, model, subject)  #returns probs not binary seg
        # img_seg = DirectionMerger.mean_fusion(HP.THRESHOLD, img_seg, probs=False)

        # ImgUtils.save_multilabel_img_as_multiple_files(HP, img_seg, subject)   # Save as several files
        img = nib.Nifti1Image(img_seg, ImgUtils.get_dwi_affine(HP.DATASET, HP.RESOLUTION))
        nib.save(img, join(HP.EXP_PATH, "segmentations", subject + "_segmentation.nii.gz"))
        print("took {}s".format(time.time() - start_time))

#Peaks to binary segmentation
# if HP.SEGMENT:
#     ExpUtils.make_dir(join(HP.EXP_PATH, "segmentations"))
#     # all_subjects = HP.TEST_SUBJECTS
#     # all_subjects = ["599469", "992774", "994273"]
#     all_subjects = HP.TRAIN_SUBJECTS + HP.VALIDATE_SUBJECTS + HP.TEST_SUBJECTS
#     for subject in all_subjects:
#         print("Get_probs subject {}".format(subject))
#
#         dataManagerSingle = DataManagerSingleSubjectById(HP, subject=subject, use_gt_mask=False)
#         trainerSingle = Trainer(model_test, dataManagerSingle)
#         img_probs, img_y = trainerSingle.get_seg_single_img(HP, probs=True)
#         # img_probs, img_y = DirectionMerger.get_seg_single_img_3_directions(HP, model, subject=subject)
#         # img_probs = DirectionMerger.mean_fusion(HP.THRESHOLD, img_probs, probs=True)
#
#         #thr: 0.4 slightly better than 0.2
#         img_seg = ImgUtils.peak_image_to_binary_mask(img_probs, len_thr=0.4)
#
#         img = nib.Nifti1Image(img_seg.astype(np.uint8), ImgUtils.get_dwi_affine(HP.DATASET, HP.RESOLUTION))
#         nib.save(img, join(HP.EXP_PATH, "segmentations", subject + "_seg.nii.gz"))

if HP.TEST:
    test_whole_subject(HP, model_test, HP.VALIDATE_SUBJECTS, "validate")
    test_whole_subject(HP, model_test, HP.TEST_SUBJECTS, "test")

if HP.GET_PROBS:
    ExpUtils.make_dir(join(HP.EXP_PATH, "probmaps"))
    # all_subjects = HP.TEST_SUBJECTS
    all_subjects = ["599469", "992774", "994273"]
    # all_subjects = HP.TRAIN_SUBJECTS + HP.VALIDATE_SUBJECTS + HP.TEST_SUBJECTS
    for subject in all_subjects:
        print("Get_probs subject {}".format(subject))

        dataManagerSingle = DataManagerSingleSubjectById(HP, subject=subject, use_gt_mask=False)
        trainerSingle = Trainer(model_test, dataManagerSingle)
        img_probs, img_y = trainerSingle.get_seg_single_img(HP, probs=True)
        # img_probs, img_y = DirectionMerger.get_seg_single_img_3_directions(HP, model, subject=subject)
        # img_probs = DirectionMerger.mean_fusion(HP.THRESHOLD, img_probs, probs=True)

        ImgUtils.save_multilabel_img_as_multiple_files_peaks(HP, img_probs, ImgUtils.get_dwi_affine(HP.DATASET, HP.RESOLUTION),
                                                             join(HP.EXP_PATH, "probmaps_" + subject))

        # ImgUtils.save_multilabel_img_as_multiple_files(HP, img_probs, ImgUtils.get_dwi_affine(HP.DATASET, HP.RESOLUTION),
        #                                                      join(HP.EXP_PATH, "probmaps_" + subject))
        # img = nib.Nifti1Image(img_probs, ImgUtils.get_dwi_affine(HP.DATASET, HP.RESOLUTION))
        # nib.save(img, join(HP.EXP_PATH, "probmaps", subject + "_probmap.nii.gz"))


