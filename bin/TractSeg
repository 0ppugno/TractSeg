#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2017 Division of Medical Image Computing, German Cancer Research Center (DKFZ)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import warnings
warnings.simplefilter("ignore", UserWarning)  # hide scipy warnings
warnings.simplefilter("ignore", FutureWarning)  # hide h5py warnings
warnings.filterwarnings("ignore", message="numpy.dtype size changed")  # hide Cython benign warning
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")  # hide Cython benign warning
import argparse
import importlib
import os
from os.path import join
import sys
from tqdm import tqdm
import nibabel as nib

from tractseg.libs.system_config import get_config_name
from tractseg.libs import exp_utils
from tractseg.libs import img_utils
from tractseg.libs import mrtrix
from tractseg.libs import plot_utils
from tractseg.libs import peak_utils
from tractseg.python_api import run_tractseg
from tractseg.libs.utils import bcolors
from tractseg.libs.system_config import SystemConfig as C


def main():
    parser = argparse.ArgumentParser(description="Segment white matter bundles in a Diffusion MRI image.",
                                        epilog="Written by Jakob Wasserthal. Please reference 'Wasserthal et al. "
                                               "TractSeg - Fast and accurate white matter tract segmentation'. "
                                               "https://doi.org/10.1016/j.neuroimage.2018.07.070'")

    parser.add_argument("-i", metavar="filepath", dest="input",
                        help="CSD peaks in MRtrix format (4D Nifti image with dimensions [x,y,z,9])", required=True)

    parser.add_argument("-o", metavar="directory", dest="output",
                        help="Output directory (default: directory of input file)")

    parser.add_argument("--single_output_file", action="store_true",
                        help="Output all bundles in one file (4D image)",
                        default=False)

    parser.add_argument("--csd_type", metavar="csd|csd_msmt|csd_msmt_5tt", choices=["csd", "csd_msmt", "csd_msmt_5tt"],
                        help="Which MRtrix constrained spherical deconvolution (CSD) is used for peak generation.\n"
                             "'csd' [DEFAULT]: Standard CSD. Very fast.\n"
                             "'csd_msmt': Multi-shell multi-tissue CSD DHollander algorithm. Medium fast. Needs "
                             "more than one b-value shell.\n"
                             "'csd_msmt_5tt': Multi-shell multi-tissue CSD 5TT. Slow on large images. Needs more "
                             "than one b-value shell."
                             "Needs a T1 image (a file 'T1w_acpc_dc_restore_brain.nii.gz' must be in the input "
                             "directory).",
                        default="csd")

    parser.add_argument("--output_type", metavar="tract_segmentation|endings_segmentation|TOM|dm_regression",
                        choices=["tract_segmentation", "endings_segmentation", "TOM", "dm_regression"],
                        help="TractSeg can segment not only bundles, but also the end regions of bundles. "
                             "Moreover it can create Tract Orientation Maps (TOM).\n"
                             "'tract_segmentation' [DEFAULT]: Segmentation of bundles (72 bundles).\n"
                             "'endings_segmentation': Segmentation of bundle end regions (72 bundles).\n"
                             "'TOM': Tract Orientation Maps (20 bundles).",
                        default="tract_segmentation")

    parser.add_argument("--bvals", metavar="filename",
                        help="bvals file. Default is '<name_of_input_file>.bvals' in same directory as input")

    parser.add_argument("--bvecs", metavar="filename",
                        help="bvecs file. Default is '<name_of_input_file>.bvecs' in same directory as input")

    parser.add_argument("--brain_mask", metavar="filename",
                        help="Manually define brain mask file. If not specified will look for file "
                             "nodif_brain_mask.nii.gz in same folder as input and if not found create one using "
                             "fsl bet. Brain mask only needed if using '--raw_diffusion_input'.")

    parser.add_argument("--raw_diffusion_input", action="store_true",
                        help="Provide a Diffusion nifti image as argument to -i. "
                             "Will calculate CSD and extract the mean peaks needed as input for TractSeg.",
                        default=False)

    parser.add_argument("--keep_intermediate_files", action="store_true",
                        help="Do not remove intermediate files like CSD output and peaks",
                        default=False)

    parser.add_argument("--preview", action="store_true", help="Save preview of some tracts as png. Requires VTK.",
                        default=False)

    parser.add_argument("--flip", action="store_true",
                        help="Flip output peaks of TOM along z axis to make compatible with MITK.",
                        default=False)

    parser.add_argument("--single_orientation", action="store_true",
                        help="Do not run model 3x along x/y/z orientation with subsequent mean fusion.",
                        default=False)

    parser.add_argument("--get_probabilities", action="store_true",
                        help="Output probability map instead of binary segmentation",
                        default=False)

    parser.add_argument("--super_resolution", action="store_true",
                        help="Keep 1.25mm resolution of model instead of downsampling back to original resolution",
                        default=False)

    parser.add_argument("--uncertainty", action="store_true",
                        help="Create uncertainty map by monte carlo dropout (https://arxiv.org/abs/1506.02142)",
                        default=False)

    parser.add_argument("--no_postprocess", action="store_true",
                        help="Deactivate simple postprocessing of segmentations (removal of small blobs)",
                        default=False)

    parser.add_argument("--preprocess", action="store_true",
                        help="Move input image to MNI space (rigid registration of FA).",
                        default=False)

    parser.add_argument("--nr_cpus", metavar="n", type=int,
                        help="Number of CPUs to use. -1 means all available CPUs (default: -1)",
                        default=-1)

    parser.add_argument('--tract_segmentation_output_dir', metavar="folder_name",
                        help="name of bundle segmentations output folder (default: bundle_segmentations)",
                        default="bundle_segmentations")

    parser.add_argument('--TOM_output_dir', metavar="folder_name",
                        help="name of TOM output folder (default: TOM)",
                        default="TOM")

    parser.add_argument('--exp_name', metavar="folder_name", help="name of experiment - ONLY FOR TESTING",
                        default=None)

    parser.add_argument('--tract_definition', metavar="TractQuerier+|AutoPTX", choices=["TractQuerier+", "AutoPTX"],
                        help="Select which tract definitions to use. 'TractQuerier+' defines tracts mainly by their"
                             "cortical start and end region. 'AutoPTX' defines tracts mainly by ROIs in white matter. "
                             "Both have their advantages and disadvantages. 'TractQuerier+' referes to the dataset "
                             "described the TractSeg NeuroImage paper. "
                             "NOTE 1: 'AutoPTX' only works for output type 'tractseg_segmentation' and "
                             "'dm_regression'. "
                             "NOTE 2: A pretrained 'AutoPTX' model is not available yet.",
                        default="TractQuerier+")

    parser.add_argument("--rescale_dm", action="store_true",
                        help="Rescale density map to [0,100] range. Original values can be very small and therefore "
                             "inconvenient to work with.",
                        default=False)

    parser.add_argument("--tract_segmentations_path", metavar="path",
                        help="Path to tract segmentations. Only needed for TOM. If empty will look for default "
                             "TractSeg output.",
                        default=None)

    parser.add_argument("--verbose", action="store_true", help="Show more intermediate output",
                        default=False)

    parser.add_argument('--version', action='version', version='TractSeg 2.0')

    args = parser.parse_args()


    #Private parameters
    input_type = "peaks"  # peaks / T1
    dropout_sampling = args.uncertainty
    threshold = 0.5          # specificity (tract_segmentation and endings_segmentation)
    peak_threshold = 0.3     # specificity (TOM)
    automatically_flip_peaks = False
    blob_size_thr = 25  # default: 50
    manual_exp_name = args.exp_name
    # if using 48 -> 30% faster runtime on CPU but needs 30GB RAM instead of 4.5GB
    # if using 5 -> 12% faster runtime on CPU
    inference_batch_size = 1
    TOM_dilation = 1  # 1 also ok for HCP because in tracking again filtered by mask
    bedpostX_input = False
    postprocess = not args.no_postprocess
    bundle_specific_postprocessing = True
    input_path = args.input
    single_orientation = args.single_orientation
    if args.output_type == "TOM":
        single_orientation = True

    if os.path.basename(input_path) == "dyads1.nii.gz":
        print("BedpostX dyads detected. Will automatically combine dyads1+2[+3].")
        bedpostX_input = True

    if manual_exp_name is None:
        config_file = get_config_name(input_type, args.output_type, dropout_sampling=dropout_sampling,
                                      tract_definition=args.tract_definition)
        Config = getattr(importlib.import_module("tractseg.experiments.pretrained_models." +
                                                 config_file), "Config")()
    else:
        Config = exp_utils.load_config_from_txt(join(C.EXP_PATH,
                                                     exp_utils.get_manual_exp_name_peaks(manual_exp_name, "Part1"),
                                                     "Hyperparameters.txt"))

    Config = exp_utils.get_correct_labels_type(Config)
    Config.CSD_TYPE = args.csd_type
    Config.KEEP_INTERMEDIATE_FILES = args.keep_intermediate_files
    Config.VERBOSE = args.verbose
    Config.SINGLE_OUTPUT_FILE = args.single_output_file
    Config.FLIP_OUTPUT_PEAKS = args.flip
    Config.PREDICT_IMG = input_path is not None
    if args.output:
        Config.PREDICT_IMG_OUTPUT = args.output
    elif Config.PREDICT_IMG:
        Config.PREDICT_IMG_OUTPUT = join(os.path.dirname(input_path), Config.TRACTSEG_DIR)
    tensor_model = Config.NR_OF_GRADIENTS == 18 * Config.NR_SLICES

    bvals, bvecs = exp_utils.get_bvals_bvecs_path(args)
    exp_utils.make_dir(Config.PREDICT_IMG_OUTPUT)

    if args.tract_segmentations_path is not None:
        tract_segmentations_path = args.tract_segmentations_path
    else:
        tract_segmentations_path = join(Config.PREDICT_IMG_OUTPUT, "bundle_segmentations")  # needed for TOM angle loss

    if args.raw_diffusion_input:
        brain_mask = exp_utils.get_brain_mask_path(Config, args)

        if args.brain_mask is None:
            brain_mask = mrtrix.create_brain_mask(input_path, Config.PREDICT_IMG_OUTPUT)

        if args.preprocess:
            input_path, bvals, bvecs, brain_mask = mrtrix.move_to_MNI_space(input_path, bvals, bvecs, brain_mask,
                                                                            Config.PREDICT_IMG_OUTPUT)

        mrtrix.create_fods(input_path, Config.PREDICT_IMG_OUTPUT, bvals, bvecs,
                           brain_mask, Config.CSD_TYPE, nr_cpus=args.nr_cpus)

    #todo: more comments? Also for bigger blocks

    if args.raw_diffusion_input:
        peak_path = join(Config.PREDICT_IMG_OUTPUT, "peaks.nii.gz")
        data_img = nib.load(peak_path)
    else:
        peak_path = input_path
        if bedpostX_input:
            data_img = peak_utils.load_bedpostX_dyads(peak_path, scale=True, tensor_model=tensor_model)
        else:
            data_img = nib.load(peak_path)
        data_img_shape = data_img.get_data().shape
        if Config.NR_OF_GRADIENTS != 1 and not (len(data_img_shape) == 4 and data_img_shape[3] == 9):
            print(bcolors.ERROR + "ERROR" + bcolors.ENDC + bcolors.BOLD +
                  ": Input image must be a peak image (nifti 4D image with dimensions [x,y,z,9]). " +
                  "If you input a Diffusion image add the option '--raw_diffusion_input'." + bcolors.ENDC)
            sys.exit()
        if Config.NR_OF_GRADIENTS == 1 and not len(data_img_shape) == 3:
            print(bcolors.ERROR + "ERROR" + bcolors.ENDC + bcolors.BOLD +
                  ": Input image must be a 3D image (nifti 3D image with dimensions [x,y,z]). " + bcolors.ENDC)
            sys.exit()

    if tensor_model:
        data_img = peak_utils.peaks_to_tensors_nifti(data_img)

    if input_type == "T1" or Config.NR_OF_GRADIENTS == 1:
        data_img = nib.Nifti1Image(data_img.get_data()[..., None], data_img.affine)  # add fourth dimension

    if args.super_resolution:
        data_img = img_utils.change_spacing_4D(data_img, new_spacing=1.25)
    data_affine = data_img.affine
    data = data_img.get_data()
    data_img = None     # free memory

    #Use Peaks + T1
    # # t1_data = nib.load("T1w_acpc_dc_restore_brain_DWIsize.nii.gz").get_data()[:,:,:,None]
    # t1_data = nib.load("T1w_acpc_dc_restore_brain.nii.gz").get_data()[:,:,:,None]
    # # needed if upsampling of peaks resulted in one pixel less (sometimes)
    # # t1_data = nib.load("T1w_acpc_dc_restore_brain.nii.gz").get_data()[1:,1:-1,1:,None]
    # data = np.concatenate((data, t1_data), axis=3)

    if Config.EXPERIMENT_TYPE == "peak_regression":
        parts = ["Part1", "Part2", "Part3", "Part4"]
        if manual_exp_name is not None and "PeaksPart1" in manual_exp_name:
            print("INFO: Only using Part1")
            parts = ["Part1"]
    else:
        # parts = ["All"]
        parts = [Config.CLASSES]

    for part in parts:
        if part.startswith("Part"):
            Config.CLASSES = "All_" + part
            Config.NR_OF_CLASSES = 3 * len(exp_utils.get_bundle_names(Config.CLASSES)[1:])

        seg = run_tractseg(data, args.output_type,
                           single_orientation=single_orientation,
                           dropout_sampling=dropout_sampling, threshold=threshold,
                           bundle_specific_postprocessing=bundle_specific_postprocessing,
                           get_probs=args.get_probabilities, peak_threshold=peak_threshold,
                           postprocess=postprocess, peak_regression_part=part,
                           input_type=input_type, blob_size_thr=blob_size_thr, nr_cpus=args.nr_cpus,
                           verbose=args.verbose, manual_exp_name=manual_exp_name,
                           inference_batch_size=inference_batch_size,
                           tract_definition=args.tract_definition, bedpostX_input=bedpostX_input,
                           tract_segmentations_path=tract_segmentations_path, TOM_dilation=TOM_dilation)

        if args.preview and Config.CLASSES not in ["All_Part2", "All_Part3", "All_Part4"]:
            print("Saving preview...")
            # plot_utils.plot_tracts(Config.CLASSES, seg, data_affine, Config.PREDICT_IMG_OUTPUT, brain_mask=None)
            plot_utils.plot_tracts_matplotlib(Config.CLASSES, seg, data, Config.PREDICT_IMG_OUTPUT,
                                              threshold=Config.THRESHOLD, exp_type=Config.EXPERIMENT_TYPE)

        if Config.EXPERIMENT_TYPE == "dm_regression":
            seg[seg < Config.THRESHOLD] = 0
            if args.rescale_dm:
                seg = img_utils.scale_to_range(seg, range(0, 100))

        if Config.SINGLE_OUTPUT_FILE:
            img = nib.Nifti1Image(seg, data_affine)
            seg = None
            if Config.EXPERIMENT_TYPE == "tract_segmentation" and dropout_sampling:
                nib.save(img, join(Config.PREDICT_IMG_OUTPUT, "bundle_uncertainties.nii.gz"))
            elif Config.EXPERIMENT_TYPE == "tract_segmentation":
                nib.save(img, join(Config.PREDICT_IMG_OUTPUT, "bundle_segmentations.nii.gz"))
            elif Config.EXPERIMENT_TYPE == "endings_segmentation":
                nib.save(img, join(Config.PREDICT_IMG_OUTPUT, "bundle_endings.nii.gz"))
            elif Config.EXPERIMENT_TYPE == "peak_regression":
                nib.save(img, join(Config.PREDICT_IMG_OUTPUT, "bundle_TOMs.nii.gz"))
            elif Config.EXPERIMENT_TYPE == "dm_regression":
                nib.save(img, join(Config.PREDICT_IMG_OUTPUT, "bundle_density_maps.nii.gz"))
            img = None  # Free memory (before we run tracking)
        else:
            if Config.EXPERIMENT_TYPE == "tract_segmentation" and dropout_sampling:
                img_utils.save_multilabel_img_as_multiple_files(Config, seg, data_affine,
                                                                Config.PREDICT_IMG_OUTPUT,
                                                                name="bundle_uncertainties")
            elif Config.EXPERIMENT_TYPE == "tract_segmentation":
                img_utils.save_multilabel_img_as_multiple_files(Config, seg, data_affine,
                                                                Config.PREDICT_IMG_OUTPUT,
                                                                name=args.tract_segmentation_output_dir)
            elif Config.EXPERIMENT_TYPE == "endings_segmentation":
                img_utils.save_multilabel_img_as_multiple_files_endings(Config, seg, data_affine,
                                                                        Config.PREDICT_IMG_OUTPUT)
            elif Config.EXPERIMENT_TYPE == "peak_regression":
                img_utils.save_multilabel_img_as_multiple_files_peaks(Config, seg, data_affine,
                                                                      Config.PREDICT_IMG_OUTPUT,
                                                                      name=args.TOM_output_dir)
            elif Config.EXPERIMENT_TYPE == "dm_regression":
                img_utils.save_multilabel_img_as_multiple_files(Config, seg, data_affine,
                                                                Config.PREDICT_IMG_OUTPUT, name="dm_regression")
            seg = None  # Free memory (before we run tracking)

        if args.preprocess and Config.EXPERIMENT_TYPE == "tract_segmentation" and Config.SINGLE_OUTPUT_FILE:
            mrtrix.move_to_subject_space(Config.PREDICT_IMG_OUTPUT)

    Config.CLASSES = "All"

    mrtrix.clean_up(Config, preprocessing_done=args.preprocess)

    # print(bcolors.GREEN + "Finished " + u'\u2713' + bcolors.ENDC)  # Color coding does not working in travis


if __name__ == '__main__':
    main()
