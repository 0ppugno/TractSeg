#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2017 Division of Medical Image Computing, German Cancer Research Center (DKFZ)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import distutils.util

import importlib
import numpy as np
import os
import warnings
import time
import nibabel as nib
from os.path import join

from tractseg.libs.Config import Config as C
from tractseg.libs.ExpUtils import ExpUtils
from tractseg.libs.Utils import Utils
from tractseg.libs.DatasetUtils import DatasetUtils
from tractseg.libs.DirectionMerger import DirectionMerger
from tractseg.libs.ImgUtils import ImgUtils
from tractseg.libs.Mrtrix import Mrtrix
from tractseg.libs.PlotUtils import PlotUtils

warnings.simplefilter("ignore", UserWarning)    #hide scipy warnings

#Settings and Hyperparameters
class HP:
    EXP_MULTI_NAME = ""              #CV Parent Dir name # leave empty for Single Bundle Experiment
    EXP_NAME = "HCP_Pytorch"       # HCP_normAfter
    MODEL = "UNet_Pytorch"     # UNet_Lasagne / UNet_Pytorch
    NUM_EPOCHS = 500
    DATA_AUGMENTATION = True
    DAUG_INFO = "Elastic(90,120)(9,11) - Scale(0.9, 1.5) - CenterDist60 - DownsampScipy(0.5,1) - Contrast(0.7,1.3) - Gaussian(0,0.05) - BrightnessMult(0.7,1.3) - RotateUltimate(-0.8,0.8) - Mirror"
    DATASET = "HCP"  # HCP / HCP_32g
    RESOLUTION = "1.25mm"  # 1.25mm (/ 2.5mm)
    FEATURES_FILENAME = "270g_125mm_peaks"  # 270g_125mm_xyz / 270g_125mm_peaks / 90g_125mm_peaks / 32g_25mm_peaks / 32g_25mm_xyz
    LABELS_FILENAME = "bundle_masks"     # bundle_masks / bundle_masks_45       #Only used when using DataManagerNifti
    DATASET_FOLDER = "HCP"  # HCP / TRACED / HCP_fusion_npy_270g_125mm / HCP_fusion_npy_32g_25mm
    LABELS_FOLDER = "bundle_masks"  # bundle_masks / bundle_masks_dm
    MULTI_PARENT_PATH = join(C.EXP_PATH, EXP_MULTI_NAME)
    EXP_PATH = join(C.EXP_PATH, EXP_MULTI_NAME, EXP_NAME)  # default path
    BATCH_SIZE = 46  # Lasagne: 56  # Lasagne combined: 42   #Pytorch: 46
    LEARNING_RATE = 0.002
    UNET_NR_FILT = 64
    LOAD_WEIGHTS = False
    WEIGHTS_PATH = ""
    TYPE = "single_direction"       # single_direction / combined
    CV_FOLD = 0
    VALIDATE_SUBJECTS = []
    TRAIN_SUBJECTS = []
    TEST_SUBJECTS = []
    TRAIN = True
    TEST = True
    SEGMENT = False
    GET_PROBS = False

    PREDICT_IMG = False
    PREDICT_IMG_OUTPUT = None
    OUTPUT_MULTIPLE_FILES = False
    TRACTSEG_DIR = "tractseg_output"
    KEEP_INTERMEDIATE_FILES = False
    CSD_RESOLUTION = "LOW"  # HIGH / LOW

    #Rarly changed:
    LABELS_TYPE = np.int16  # Binary: np.int16, Regression: np.float32
    THRESHOLD = 0.5         # Binary: 0.5, Regression: 0.01 ?
    TEST_TIME_DAUG = False
    SLICE_DIRECTION = "x"   #no effect at the moment     # x, y, z  (combined needs z)
    USE_VISLOGGER = False
    INFO = "74 BNew, DMNifti, newSplit, 90gAnd270g, NormBeforeDAug, Fusion: 32gAnd270g"
    SAVE_WEIGHTS = True
    NR_OF_CLASSES = len(ExpUtils.get_bundle_names())
    SEG_INPUT = "Peaks"     # Gradients/ Peaks
    NR_SLICES = 1           # adapt manually: NR_OF_GRADIENTS in UNet.py and get_batch... in train() and in get_seg_prediction()
    PRINT_FREQ = 20
    NORMALIZE_DATA = True
    BEST_EPOCH = 0
    INPUT_DIM = (144, 144)
    VERBOSE = True

parser = argparse.ArgumentParser(description="Segment white matter bundles in a Diffusion MRI image.",
                                    epilog="Written by Jakob Wasserthal. Please reference 'Wasserthal et al. " +
                                           "Direct White Matter Bundle Segmentation using Stacked U-Nets. https://arxiv.org/abs/1703.02036)'")
parser.add_argument("-i", metavar="filepath", dest="input", help="Diffusion Input image path (Nifti image)", required=True)
parser.add_argument("-o", metavar="directory", dest="output", help="Output directory")
parser.add_argument("--output_multiple_files", action="store_true", help="Create extra output file for each bundle", default=False)
parser.add_argument("--csd_type", metavar="type", choices=["csd", "csd_msmt", "csd_msmt_5tt"],
                    help="Which MRtrix constrained spherical deconvolution (CSD) is used for peak generation.\n" +
                         "'csd' [DEFAULT]: Standard CSD. Very fast. Only uses b=1000mm/s^2. (if input image contains more shells all but b=1000mm/s^2 are discarded)\n" +
                         "'csd_msmt': Multi-shell multi-tissue CSD DHollander algorithm. Medium fast. Needs more than one b-value shell.\n" +
                         "'csd_msmt_5tt': Multi-shell multi-tissue CSD 5TT. Slow on large images. Needs more than one b-value shell." +
                         "Needs a T1 image (a file T1w_acpc_dc_restore_brain.nii.gz must be in the input directory).", default="csd")
parser.add_argument("--bvals", metavar="filename", help="bvals file. Default is 'Diffusion.bvals' in same directory as input")  #todo: change default
parser.add_argument("--bvecs", metavar="filename", help="bvecs file. Default is 'Diffusion.bvecs' in same directory as input")
parser.add_argument("--brain_mask", metavar="filename", help="brain mask file. If not specified will automatically be generated with fsl bet")
parser.add_argument("--verbose", action="store_true", help="Show more intermediate output", default=False)
parser.add_argument("--skip_peak_extraction", action="store_true", help="Do not calculate input peaks. You have to provide them yourself as argument to -i", default=False)
parser.add_argument("--keep_intermediate_files", action="store_true", help="Do not remove intermediate files like CSD output and peaks", default=False)
parser.add_argument("--preview", action="store_true", help="Save preview of some tracts as png. Faster to view than nifti output image. Requires VTK.", default=False)
parser.add_argument("--flip", action="store_true", help="Use model that works independently of the image orientation. Slightly worse results than standard model.", default=False)
parser.add_argument('--version', action='version', version='TractSeg 1.0')
args = parser.parse_args()

HP.PREDICT_IMG = args.input is not None
if args.output:
    HP.PREDICT_IMG_OUTPUT = join(args.output, HP.TRACTSEG_DIR)
elif HP.PREDICT_IMG:
    HP.PREDICT_IMG_OUTPUT = join(os.path.dirname(args.input), HP.TRACTSEG_DIR)
HP.OUTPUT_MULTIPLE_FILES = args.output_multiple_files
HP.VERBOSE = args.verbose
HP.KEEP_INTERMEDIATE_FILES = args.keep_intermediate_files
HP.CSD_TYPE = args.csd_type
HP.TRAIN = False
HP.TEST = False
HP.SEGMENT = False
HP.GET_PROBS = False
HP.LOAD_WEIGHTS = True
if args.flip:
    HP.WEIGHTS_PATH = join(C.TRACT_SEG_HOME, "pretrained_weights_Mir.npz")
else:
    HP.WEIGHTS_PATH = join(C.TRACT_SEG_HOME, "pretrained_weights.npz")
ModelClass = getattr(importlib.import_module("tractseg.models." + HP.MODEL), HP.MODEL)   # run early before code changes in background

if HP.VERBOSE:
    print("Hyperparameters:")
    ExpUtils.print_HPs(HP)

Utils.download_pretrained_weights(flip=args.flip)
bvals, bvecs = ExpUtils.get_bvals_bvecs_path(args)
brain_mask = ExpUtils.get_brain_mask_path(HP, args)
ExpUtils.make_dir(HP.PREDICT_IMG_OUTPUT)

if not args.skip_peak_extraction:
    if not args.brain_mask:
        Mrtrix.create_brain_mask(args.input, HP.PREDICT_IMG_OUTPUT)
    Mrtrix.create_fods(args.input, HP.PREDICT_IMG_OUTPUT, bvals, bvecs, brain_mask, HP.CSD_TYPE)

start_time = time.time()
if args.skip_peak_extraction:
    data_img = nib.load(args.input)
else:
    data_img = nib.load(join(HP.PREDICT_IMG_OUTPUT, "peaks.nii.gz"))
data, transformation = DatasetUtils.pad_and_scale_img_to_square_img(data_img.get_data(), target_size=144)

model = ModelClass(HP)
seg_xyz, gt = DirectionMerger.get_seg_single_img_3_directions(HP, model, data=data, scale_to_world_shape=False)
seg = DirectionMerger.mean_fusion(HP.THRESHOLD, seg_xyz, probs=False)

seg = DatasetUtils.cut_and_scale_img_back_to_original_img(seg, transformation)
ExpUtils.print_verbose(HP, "Took {}s".format(round(time.time() - start_time, 2)))

if args.preview:
    print("Saving preview...")
    PlotUtils.plot_tracts(seg, HP.PREDICT_IMG_OUTPUT)

if HP.OUTPUT_MULTIPLE_FILES:
    ImgUtils.save_multilabel_img_as_multiple_files(seg, data_img.get_affine(), HP.PREDICT_IMG_OUTPUT)  # Save as several files
else:
    img = nib.Nifti1Image(seg, data_img.get_affine())
    nib.save(img, join(HP.PREDICT_IMG_OUTPUT, "bundle_segmentations.nii.gz"))

Mrtrix.clean_up(HP)