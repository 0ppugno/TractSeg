#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2017 Division of Medical Image Computing, German Cancer Research Center (DKFZ)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import warnings
warnings.simplefilter("ignore", UserWarning)    #hide scipy warnings
warnings.simplefilter("ignore", FutureWarning)    #hide h5py warnings

import argparse
import importlib
import numpy as np
import os
import time
import nibabel as nib
from os.path import join

from tractseg.libs.Config import Config as C
from tractseg.libs.ExpUtils import ExpUtils
from tractseg.libs.Utils import Utils
from tractseg.libs.DatasetUtils import DatasetUtils
from tractseg.libs.DirectionMerger import DirectionMerger
from tractseg.libs.ImgUtils import ImgUtils
from tractseg.libs.Mrtrix import Mrtrix
from tractseg.libs.PlotUtils import PlotUtils
from tractseg.libs.DataManagers import DataManagerSingleSubjectByFile
from tractseg.libs.Trainer import Trainer

'''
Usage:
TractSeg -i peaks.nii.gz --output_multiple_files --skip_peak_extraction
'''

parser = argparse.ArgumentParser(description="Segment white matter bundles in a Diffusion MRI image.",
                                    epilog="Written by Jakob Wasserthal. Please reference 'Wasserthal et al. " +
                                           "Direct White Matter Bundle Segmentation using Stacked U-Nets. https://arxiv.org/abs/1703.02036'")
parser.add_argument("-i", metavar="filepath", dest="input", help="Diffusion Input image path (Nifti image)", required=True)
parser.add_argument("-o", metavar="directory", dest="output", help="Output directory")
parser.add_argument("--output_multiple_files", action="store_true", help="Create extra output file for each bundle", default=False)
parser.add_argument("--csd_type", metavar="csd|csd_msmt|csd_msmt_5tt", choices=["csd", "csd_msmt", "csd_msmt_5tt"],
                    help="Which MRtrix constrained spherical deconvolution (CSD) is used for peak generation.\n" +
                         "'csd' [DEFAULT]: Standard CSD. Very fast. Only uses b=1000mm/s^2. (if input image contains more shells all but b=1000mm/s^2 are discarded)\n" +
                         "'csd_msmt': Multi-shell multi-tissue CSD DHollander algorithm. Medium fast. Needs more than one b-value shell.\n" +
                         "'csd_msmt_5tt': Multi-shell multi-tissue CSD 5TT. Slow on large images. Needs more than one b-value shell." +
                         "Needs a T1 image (a file 'T1w_acpc_dc_restore_brain.nii.gz' must be in the input directory).", default="csd")
parser.add_argument("--output_type", metavar="tract_segmentation|endings_segmentation|TOM", choices=["tract_segmentation", "endings_segmentation", "TOM"],
                    help="TractSeg can segment not only bundles, but also the end regions of bundles. Moreover it can create Tract Orientation Maps (TOM).\n" +
                         "'tract_segmentation' [DEFAULT]: Segmentation of bundles (72 bundles).\n" +
                         "'endings_segmentation': Segmentation of bundle end regions (20 bundles).\n" +
                         "'TOM': Tract Orientation Maps (20 bundles).",
                    default="tract_segmentation")
parser.add_argument("--bvals", metavar="filename", help="bvals file. Default is '<name_of_input_file>.bvals' in same directory as input")  #todo: change default
parser.add_argument("--bvecs", metavar="filename", help="bvecs file. Default is '<name_of_input_file>.bvecs' in same directory as input")
parser.add_argument("--brain_mask", metavar="filename", help="brain mask file. If not specified will automatically be generated with fsl bet")
parser.add_argument("--verbose", action="store_true", help="Show more intermediate output", default=False)
parser.add_argument("--skip_peak_extraction", action="store_true", help="Do not calculate input peaks. You have to provide them yourself as argument to -i", default=False)
parser.add_argument("--keep_intermediate_files", action="store_true", help="Do not remove intermediate files like CSD output and peaks", default=False)
parser.add_argument("--preview", action="store_true", help="Save preview of some tracts as png. Faster to view than nifti output image. Requires VTK.", default=False)
parser.add_argument("--flip", action="store_true", help="Use model that works independently of the image orientation. Slightly worse results than standard model.", default=False)
parser.add_argument('--version', action='version', version='TractSeg 1.2')
args = parser.parse_args()


if args.output_type == "tract_segmentation":
    config = "TractSeg_12g90g270g_125mm_DAugAll"
elif args.output_type == "endings_segmentation":
    config = "EndingsSeg_12g90g270g_125mm_DAugAll"
elif args.output_type == "TOM":
    config = "Peaks20_12g90g270g_125mm"
HP = getattr(importlib.import_module("tractseg.config.PretrainedModels." + config), "HP")()

HP.PREDICT_IMG = args.input is not None
if args.output:
    HP.PREDICT_IMG_OUTPUT = join(args.output, HP.TRACTSEG_DIR)
elif HP.PREDICT_IMG:
    HP.PREDICT_IMG_OUTPUT = join(os.path.dirname(args.input), HP.TRACTSEG_DIR)
HP.OUTPUT_MULTIPLE_FILES = args.output_multiple_files
HP.VERBOSE = args.verbose
HP.KEEP_INTERMEDIATE_FILES = args.keep_intermediate_files
HP.CSD_TYPE = args.csd_type
HP.TRAIN = False
HP.TEST = False
HP.SEGMENT = False
HP.GET_PROBS = False
HP.LOAD_WEIGHTS = True

if args.flip:
    HP.WEIGHTS_PATH = join(C.TRACT_SEG_HOME, "pretrained_weights_Mir_v1.npz")
else:
    if HP.EXPERIMENT_TYPE == "tract_segmentation":
        HP.WEIGHTS_PATH = join(C.TRACT_SEG_HOME, "pretrained_weights_tract_segmentation_v1.npz")
        # HP.WEIGHTS_PATH = join(C.NETWORK_DRIVE, "hcp_exp_nodes", "TractSeg_270g_125mm_run2", "best_weights_ep136.npz")
    elif HP.EXPERIMENT_TYPE == "endings_segmentation":
        HP.WEIGHTS_PATH = join(C.TRACT_SEG_HOME, "pretrained_weights_endings_segmentation_v1.npz")
        # HP.WEIGHTS_PATH = join(C.NETWORK_DRIVE, "hcp_exp_nodes", "EndingsSeg_12g90g270g_125mm_DAugAll", "best_weights_ep16.npz")
    elif HP.EXPERIMENT_TYPE == "peak_regression":
        HP.WEIGHTS_PATH = join(C.TRACT_SEG_HOME, "pretrained_weights_peak_regression_v1.npz")
        # HP.WEIGHTS_PATH = join(C.NETWORK_DRIVE, "hcp_exp_nodes", "Peaks20_270g_125mm_LW5", "best_weights_ep144.npz")

    print("Loading weights from: {}".format(HP.WEIGHTS_PATH))
ModelClass = getattr(importlib.import_module("tractseg.models." + HP.MODEL), HP.MODEL)   # run early before code changes in background

if HP.EXPERIMENT_TYPE == "peak_regression":
    HP.NR_OF_CLASSES = 3*len(ExpUtils.get_bundle_names(HP.CLASSES)[1:])
else:
    HP.NR_OF_CLASSES = len(ExpUtils.get_bundle_names(HP.CLASSES)[1:])

if HP.VERBOSE:
    print("Hyperparameters:")
    ExpUtils.print_HPs(HP)

Utils.download_pretrained_weights(experiment_type=HP.EXPERIMENT_TYPE)
bvals, bvecs = ExpUtils.get_bvals_bvecs_path(args)
brain_mask = ExpUtils.get_brain_mask_path(HP, args)
ExpUtils.make_dir(HP.PREDICT_IMG_OUTPUT)

if not args.skip_peak_extraction:
    if not args.brain_mask:
        Mrtrix.create_brain_mask(args.input, HP.PREDICT_IMG_OUTPUT)
    Mrtrix.create_fods(args.input, HP.PREDICT_IMG_OUTPUT, bvals, bvecs, brain_mask, HP.CSD_TYPE)

start_time = time.time()
if args.skip_peak_extraction:
    data_img = nib.load(args.input)
else:
    data_img = nib.load(join(HP.PREDICT_IMG_OUTPUT, "peaks.nii.gz"))
data, transformation = DatasetUtils.pad_and_scale_img_to_square_img(data_img.get_data(), target_size=HP.INPUT_DIM[0])

model = ModelClass(HP)

if HP.EXPERIMENT_TYPE == "tract_segmentation" or HP.EXPERIMENT_TYPE == "endings_segmentation":
    seg_xyz, gt = DirectionMerger.get_seg_single_img_3_directions(HP, model, data=data, scale_to_world_shape=False)
    seg = DirectionMerger.mean_fusion(HP.THRESHOLD, seg_xyz, probs=False)
elif HP.EXPERIMENT_TYPE == "peak_regression":
    dataManagerSingle = DataManagerSingleSubjectByFile(HP, data=data)
    trainerSingle = Trainer(model, dataManagerSingle)
    seg, img_y = trainerSingle.get_seg_single_img(HP, probs=True, scale_to_world_shape=False)
    #3 dir for Peaks -> not working (?)
    # seg_xyz, gt = DirectionMerger.get_seg_single_img_3_directions(HP, model, data=data, scale_to_world_shape=False)
    # seg = DirectionMerger.mean_fusion(HP.THRESHOLD, seg_xyz, probs=True)

seg = DatasetUtils.cut_and_scale_img_back_to_original_img(seg, transformation)
ExpUtils.print_verbose(HP, "Took {}s".format(round(time.time() - start_time, 2)))

if args.preview:
    print("Saving preview...")
    PlotUtils.plot_tracts(seg, HP.PREDICT_IMG_OUTPUT)

if HP.OUTPUT_MULTIPLE_FILES:
    if HP.EXPERIMENT_TYPE == "tract_segmentation":
        ImgUtils.save_multilabel_img_as_multiple_files(HP, seg, data_img.get_affine(), HP.PREDICT_IMG_OUTPUT)
    elif HP.EXPERIMENT_TYPE == "endings_segmentation":
        ImgUtils.save_multilabel_img_as_multiple_files_endings(HP, seg, data_img.get_affine(), HP.PREDICT_IMG_OUTPUT)
    elif HP.EXPERIMENT_TYPE == "peak_regression":
        ImgUtils.save_multilabel_img_as_multiple_files_peaks(HP, seg, data_img.get_affine(), HP.PREDICT_IMG_OUTPUT)
else:
    img = nib.Nifti1Image(seg, data_img.get_affine())
    if HP.EXPERIMENT_TYPE == "tract_segmentation":
        nib.save(img, join(HP.PREDICT_IMG_OUTPUT, "bundle_segmentations.nii.gz"))
    elif HP.EXPERIMENT_TYPE == "endings_segmentation":
        nib.save(img, join(HP.PREDICT_IMG_OUTPUT, "bundle_endings.nii.gz"))
    elif HP.EXPERIMENT_TYPE == "peak_regression":
        nib.save(img, join(HP.PREDICT_IMG_OUTPUT, "bundle_TOMs.nii.gz"))

Mrtrix.clean_up(HP)